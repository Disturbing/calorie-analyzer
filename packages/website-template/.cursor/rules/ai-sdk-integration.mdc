---
description: AI SDK integration patterns with AI Elements
globs: *.ts,*.tsx,api/**/*
---

# AI SDK Integration with AI Elements

This guide covers integrating AI SDK hooks and utilities with AI Elements components for building complete AI interfaces.

## Core AI SDK Hooks

### 1. useChat Hook
The primary hook for chat interfaces:
```typescript
import { useChat } from '@ai-sdk/react';
import { Message, MessageContent } from '@/components/ai-elements/message';
import { Response } from '@/components/ai-elements/response';

const { 
  messages, 
  input, 
  handleInputChange, 
  handleSubmit, 
  status, 
  error,
  reload,
  stop
} = useChat({
  api: '/api/chat',
  onError: (error) => console.error('Chat error:', error),
});
```

### 2. Message Processing Pattern
Handle different message parts and types:
```typescript
{messages.map((message) => (
  <Message from={message.role} key={message.id}>
    <MessageContent>
      {message.parts.map((part, index) => {
        switch (part.type) {
          case 'text':
            return <Response key={index}>{part.text}</Response>;
          case 'image':
            return <Image key={index} src={part.url} alt={part.alt} />;
          case 'tool-call':
            return <Tool key={index} call={part} />;
          case 'tool-result':
            return <ToolResult key={index} result={part} />;
          default:
            return null;
        }
      })}
    </MessageContent>
  </Message>
))}
```

### 3. Status-Aware UI
React to chat status changes:
```typescript
import { Loader } from '@/components/ai-elements/loader';
import { Actions, Action } from '@/components/ai-elements/actions';

// Show loader during streaming
{status === 'streaming' && <Loader />}

// Conditional actions based on status
<Actions>
  {status === 'streaming' ? (
    <Action onClick={stop} label="Stop">
      <StopIcon />
    </Action>
  ) : (
    <Action onClick={reload} label="Regenerate">
      <RefreshIcon />
    </Action>
  )}
</Actions>
```

## Backend API Patterns

### 1. Basic Chat Route
```typescript
// api/chat/route.ts
import { streamText, convertToModelMessages } from 'ai';
import { openai } from '@/lib/ai/openai'; // or your provider

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai('gpt-4'),
    messages: convertToModelMessages(messages),
    system: 'You are a helpful assistant.',
  });

  return result.toUIMessageStreamResponse();
}
```

### 2. Tool Integration
```typescript
import { tool } from 'ai';
import { z } from 'zod';

const weatherTool = tool({
  description: 'Get weather information',
  parameters: z.object({
    location: z.string().describe('Location to get weather for'),
  }),
  execute: async ({ location }) => {
    // Fetch weather data
    return { temperature: 72, conditions: 'sunny' };
  },
});

const result = streamText({
  model: openai('gpt-4'),
  messages: convertToModelMessages(messages),
  tools: { weather: weatherTool },
});
```

### 3. Multi-turn Conversations
```typescript
// Handle conversation context properly
const result = streamText({
  model: openai('gpt-4'),
  messages: convertToModelMessages(messages),
  system: `You are an AI assistant. Previous context is maintained through the messages array.`,
  maxTokens: 1000,
  temperature: 0.7,
});
```

## Advanced Integration Patterns

### 1. Suggestion Integration
```typescript
import { Suggestion } from '@/components/ai-elements/suggestion';

const suggestions = [
  'Explain quantum computing',
  'Write a Python function',
  'Summarize this document'
];

<div className="suggestions">
  {suggestions.map((suggestion) => (
    <Suggestion 
      key={suggestion}
      onClick={() => append({ role: 'user', content: suggestion })}
    >
      {suggestion}
    </Suggestion>
  ))}
</div>
```

### 2. File Upload with AI Processing
```typescript
import { useChat } from '@ai-sdk/react';

const { append } = useChat();

const handleFileUpload = async (file: File) => {
  const formData = new FormData();
  formData.append('file', file);
  
  // Upload and process file
  const response = await fetch('/api/upload', {
    method: 'POST',
    body: formData,
  });
  
  const { fileUrl, analysis } = await response.json();
  
  // Send to AI with file context
  append({
    role: 'user',
    content: `Please analyze this file: ${fileUrl}`,
    attachments: [{ url: fileUrl, contentType: file.type }]
  });
};
```

### 3. Streaming with Citations
```typescript
// Backend: Include sources in streaming response
import { InlineCitation } from '@/components/ai-elements/inline-citation';

const result = streamText({
  model: openai('gpt-4'),
  messages: convertToModelMessages(messages),
  onFinish: async ({ text, finishReason, usage }) => {
    // Log completion details
    console.log('Completion:', { finishReason, usage });
  },
});

// Frontend: Render citations
<Response>
  {messageText}
  <InlineCitation source={{ title: 'Source Title', url: 'https://...' }}>
    [1]
  </InlineCitation>
</Response>
```

### 4. Error Handling
```typescript
const { error } = useChat({
  onError: (error) => {
    // Handle different error types
    if (error.message.includes('rate limit')) {
      toast.error('Too many requests. Please try again later.');
    } else if (error.message.includes('network')) {
      toast.error('Network error. Check your connection.');
    } else {
      toast.error('Something went wrong. Please try again.');
    }
  },
});

// Display error state in UI
{error && (
  <div className="error-message">
    <p>Error: {error.message}</p>
    <Action onClick={reload} label="Retry">
      <RefreshIcon />
    </Action>
  </div>
)}
```

## Performance Optimization

### 1. Message Virtualization
For long conversations, consider virtualization:
```typescript
import { FixedSizeList as List } from 'react-window';

const MessageList = ({ messages }) => (
  <List
    height={600}
    itemCount={messages.length}
    itemSize={100}
    itemData={messages}
  >
    {({ index, style, data }) => (
      <div style={style}>
        <Message from={data[index].role}>
          <MessageContent>
            <Response>{data[index].content}</Response>
          </MessageContent>
        </Message>
      </div>
    )}
  </List>
);
```

### 2. Debounced Input
For real-time features:
```typescript
import { useDebouncedCallback } from 'use-debounce';

const debouncedSubmit = useDebouncedCallback(
  (value: string) => {
    if (value.trim()) {
      append({ role: 'user', content: value });
    }
  },
  500
);
```

### 3. Selective Re-rendering
Use React.memo strategically:
```typescript
const MessageItem = React.memo(({ message }) => (
  <Message from={message.role}>
    <MessageContent>
      <Response>{message.content}</Response>
    </MessageContent>
  </Message>
), (prevProps, nextProps) => {
  return prevProps.message.id === nextProps.message.id &&
         prevProps.message.content === nextProps.message.content;
});
```

## Type Safety

### 1. Message Type Definitions
```typescript
import type { UIMessage } from 'ai';

interface ExtendedMessage extends UIMessage {
  metadata?: {
    sources?: Array<{ title: string; url: string }>;
    confidence?: number;
    processingTime?: number;
  };
}
```

### 2. Tool Result Types
```typescript
interface WeatherResult {
  temperature: number;
  conditions: string;
  humidity: number;
}

const WeatherDisplay = ({ result }: { result: WeatherResult }) => (
  <div className="weather-result">
    <p>Temperature: {result.temperature}Â°F</p>
    <p>Conditions: {result.conditions}</p>
    <p>Humidity: {result.humidity}%</p>
  </div>
);
```

## Testing Patterns

### 1. Mock useChat Hook
```typescript
// In tests
const mockUseChat = {
  messages: [],
  input: '',
  handleInputChange: jest.fn(),
  handleSubmit: jest.fn(),
  status: 'ready' as const,
  error: null,
};

jest.mock('@ai-sdk/react', () => ({
  useChat: () => mockUseChat,
}));
```

### 2. Component Testing
```typescript
import { render, screen, fireEvent } from '@testing-library/react';
import { ChatInterface } from './ChatInterface';

test('sends message on submit', async () => {
  render(<ChatInterface />);
  
  const input = screen.getByPlaceholderText('Type your message...');
  const submit = screen.getByRole('button', { name: /send/i });
  
  fireEvent.change(input, { target: { value: 'Hello AI' } });
  fireEvent.click(submit);
  
  expect(mockUseChat.handleSubmit).toHaveBeenCalled();
});
```